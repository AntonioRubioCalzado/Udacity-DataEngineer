{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select paht where the data is located by appending the current workspace (/home/workspace) to /event_data/data.\n",
    "\n",
    "filepath = os.getcwd() + '/event_data/data/'\n",
    "\n",
    "# With the following loop, we create a list with all the diferent absolute paths of each csv file.\n",
    "\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "        file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We read each csv file on its corresponding path in the filepath list.\n",
    "# For each of them, we iterate over its rows and store them in the list full_data_rows_list\n",
    "\n",
    "full_data_rows_list = [] \n",
    "for f in file_path_list:\n",
    "\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "\n",
    "# Now we create an event data csv file (event_datafile_full.csv) that will be used to insert into Cassandra tables.\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                     'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the append of the csv files is: 6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(f\"The number of rows in the append of the csv files is: {sum(1 for line in f)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's make a connection to an Apache Cassandra instance in 127.0.0.1\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We create the keyspace sparkifydb in Cassandra, with replication factor 1. \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkifydb\n",
    "    WITH REPLICATION={'class': 'SimpleStrategy','replication_factor': 1}\"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# With the next command we set the keyspace to the sparkifydb keyspace that's been just created.\n",
    "try:\n",
    "    session.set_keyspace('sparkifydb')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    " 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    " 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    " 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the table session_history with the fields sessionId, itemInSession, artist, song, length especifying \n",
    "# sessionId and itemInSession as Primary Key (sessionId as partition key and itemInSession as clustering key).\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS session_history\"\n",
    "query = query + \"(sessionId int, \\\n",
    "                  itemInSession int, \\\n",
    "                  artist text, \\\n",
    "                  song text, \\\n",
    "                  length float, \\\n",
    "                  PRIMARY KEY(sessionId, itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We iterate over the lines in the csv created in the first part of the Jupyter Notebook and select the corresponding\n",
    "# fields with its datatype to insert into the Cassandra table session_history.\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO session_history (sessionId, itemInSession, artist, song, length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist                             song      length\n",
      "0  Faithless  Music Matters (Mark Knight Dub)  495.307312\n"
     ]
    }
   ],
   "source": [
    "# We fix the query asked in exercise 1 and create a pandas dataframe with the execution of such a query.\n",
    "\n",
    "query = \"select * from session_history WHERE sessionId=338 AND itemInSession=4\"\n",
    "session_history = pd.DataFrame(list(session.execute(query)))\n",
    "\n",
    "# We select the fields that we need from the previous dataframe.\n",
    "\n",
    "solution_1 = session_history[['artist', 'song', 'length']]\n",
    "print(solution_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Repetition of the process for other queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              artist                                               song  \\\n",
      "0   Down To The Bone                                 Keep On Keepin' On   \n",
      "1       Three Drives                                        Greece 2000   \n",
      "2  Sebastien Tellier                                          Kilometer   \n",
      "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
      "\n",
      "  iteminsession firstname lastname  \n",
      "0             0    Sylvie     Cruz  \n",
      "1             1    Sylvie     Cruz  \n",
      "2             2    Sylvie     Cruz  \n",
      "3             3    Sylvie     Cruz  \n"
     ]
    }
   ],
   "source": [
    "# Create the table song_for_user_in_session_history with the fields artist, song, sessionId, itemInSession, firstName, lastName and userId \n",
    "# specifying userId,sessionId and itemInSession as Primary Key (userId and sessionId as composite partition key) \n",
    "# and itemInSession as clustering key.\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_for_user_in_session_history\"\n",
    "query = query + \"(artist text, \\\n",
    "                  song text, \\\n",
    "                  sessionId text, \\\n",
    "                  itemInSession text, \\\n",
    "                  firstName text, \\\n",
    "                  lastName text, \\\n",
    "                  userId text, \\\n",
    "                  PRIMARY KEY((userId, sessionId), itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# We iterate over the lines in the csv created in the first part of the Jupyter Notebook and select the corresponding\n",
    "# fields with its datatype to insert into the Cassandra table song_for_user_in_session_history.\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_for_user_in_session_history (artist, song, sessionId, itemInSession, firstName, lastName, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[0], line[9], line[8], line[3], line[1], line[4], line[10]))    \n",
    "\n",
    "# We fix the query asked in exercise 2 and create a pandas dataframe with the execution of such a query.\n",
    "        \n",
    "query = \"select * from song_for_user_in_session_history WHERE userId='10' AND sessionId='182'\"\n",
    "song_for_user_in_session_history = pd.DataFrame(list(session.execute(query)))\n",
    "#print(user_for_session_history)\n",
    "\n",
    "# We select the fields that we need from the previous dataframe.\n",
    "solution_2 = song_for_user_in_session_history[['artist', 'song', 'iteminsession', 'firstname', 'lastname']]\n",
    "print(solution_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    firstname lastname\n",
      "0  Jacqueline    Lynch\n",
      "1       Tegan   Levine\n",
      "2        Sara  Johnson\n"
     ]
    }
   ],
   "source": [
    "# Create the table user_for_song_in_session_history with the fields firstName, lastName, song and userId, \n",
    "# specifying song and userId Primary Key song as partition key and userId as clustering key.\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_for_song_in_session_history\"\n",
    "query = query + \"(firstName text, lastName text, song text, userId text, PRIMARY KEY(song, userId))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# We iterate over the lines in the csv created in the first part of the Jupyter Notebook and select the corresponding\n",
    "# fields with its datatype to insert into the Cassandra table user_for_song_in_session_history.\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_for_song_in_session_history (firstName, lastName, song, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[1], line[4], line[9], line[10]))    \n",
    "\n",
    "# We fix the query asked in exercise 3 and create a pandas dataframe with the execution of such a query.\n",
    "\n",
    "query = \"select * from user_for_song_in_session_history WHERE song='All Hands Against His Own'\"\n",
    "user_for_song_in_session_history = pd.DataFrame(list(session.execute(query)))\n",
    "#print(user_for_song_in_session_history)\n",
    "\n",
    "# We select the fields that we need from the previous dataframe.\n",
    "\n",
    "solution_3 = user_for_song_in_session_history[['firstname', 'lastname']]\n",
    "print(solution_3)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We create a list with the different queries to drop the three tables created and iterate over them executing the drop command.\n",
    "\n",
    "queries = [\"drop table if exists session_history\",\n",
    "           \"drop table if exists song_for_user_in_session_history\",\n",
    "           \"drop table if exists user_for_song_in_session_history\"]\n",
    "\n",
    "for query in queries:\n",
    "    try:\n",
    "        rows = session.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
