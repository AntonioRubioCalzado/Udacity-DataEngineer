{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "\n",
    "### Project Summary\n",
    "\n",
    "The purpose of the data engineering capstone project is to combine the techniques learned throughout the program.\n",
    "In this project, I have chosen to complete the project provided for me by Udacity: We are going to analyse immigration data on US and enriched it with some other information that help us determine analytical questions. \n",
    "\n",
    "\n",
    "To automate the different tasks, we are going to take the different information to the AWS cloud and we are going to set up a data warehouse in Redshift, which will be fed from S3 periodically by jobs launched by Apache Airflow.\n",
    "\n",
    "### Project Structure\n",
    "\n",
    "The project follows the follow steps:\n",
    "\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1. Scope the Project and Gather Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.1. Identify and gather the data that will be used for the project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For this project we are going to use the I94 data provided, with information about immigration into US. This would be our main source of data. We are going to enrich it with US demographic data, global temperature data, airports data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.2. Explain what end use cases it will be prepared the data for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We are going to create a data model in a data warehose that allows us to extract analytical information about different aspects of immigration such as:\n",
    "* Visitors by country/airline.\n",
    "* Effect of temperature/Demographical patterns on the trend of visitors.\n",
    "\n",
    "Another case of use that could be performed after completing the data warehouse would be feeding other US systems that needs this data or developing some machine learning algorithms to design a tourists recommendation engine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2. Explore and Assess the Data.\n",
    "\n",
    "### 2.1. Overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We are going to apply some exploratory analysis of the different sources of data, in order to understand the different information better. We are going to describe, clean and join those tables to check what data model is better for this case of use.\n",
    "\n",
    "We are going to analyse each datasource separately and later we will see how to build a robust model, but before this we import the Python libraries necessaries for executing the code.\n",
    "\n",
    "**I would like to point that this Jupyter notebook is going to be used as a guide of what is going to be scripted separately. For example, for the exploratory analysis in this notebook I'm using Pandas but in the scripts we are going to productivize this in Spark.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import of libraries for this exploratory analysis.\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.2. I94-Immigration- Data\n",
    "As wikipedia explains on their website https://en.wikipedia.org/wiki/Form_I-94,\n",
    "the I-94 is a document that proof of legal entry into the US. \n",
    "\n",
    "More exactly, *Form I-94, the Arrival-Departure Record Card, is a form used by U.S. Customs and Border Protection (CBP) intended to keep track of the arrival and departure to/from the United States of people who are not United States citizens or lawful permanent residents (with the exception of those who are entering using the Visa Waiver Program or Compact of Free Association, using Border Crossing Cards, re-entering via automatic visa revalidation, or entering temporarily as crew members). While the form is usually issued by CBP at ports of entry or deferred inspection sites, USCIS can issue an equivalent as part of the Form I-797A approval notice for a Form I-129 petition for an alien worker or a Form I-539 application for extension of stay or change of status (in the case that the alien is already in the United States).*\n",
    "\n",
    "In our case of use, we have all the I94 data of the year 2016 in the path /data/18-83510-I94-Data-2016, splitted my month and in format sas7bdat (SAS binary database storage). This 12 datasets have almost 41 million rows and 28 columns. To simplify, we have taken the data of January, which has 2.847.924 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fname = '../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat'\n",
    "df_immigration = pd.read_sas(immigration_fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>346608285.0</td>\n",
       "      <td>424</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>346627585.0</td>\n",
       "      <td>424</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20480.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381092385.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381087885.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381078685.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    7.0  2016.0     1.0   101.0   101.0     BOS  20465.0      1.0      MA   \n",
       "1    8.0  2016.0     1.0   101.0   101.0     BOS  20465.0      1.0      MA   \n",
       "2    9.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "3   10.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "4   11.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...         NaN      NaN   1996.0       D/S      M    NaN   \n",
       "1      NaN   ...         NaN      NaN   1996.0       D/S      M    NaN   \n",
       "2  20480.0   ...         NaN        M   1999.0  07152016      F    NaN   \n",
       "3  20499.0   ...         NaN        M   1971.0  07152016      F    NaN   \n",
       "4  20499.0   ...         NaN        M   2004.0  07152016      M    NaN   \n",
       "\n",
       "  airline       admnum fltno visatype  \n",
       "0      LH  346608285.0   424       F1  \n",
       "1      LH  346627585.0   424       F1  \n",
       "2      AF  381092385.0   338       B2  \n",
       "3      AF  381087885.0   338       B2  \n",
       "4      AF  381078685.0   338       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This table will be the fact table of our data model. All the dimensions will enrich the study and analysis of this one.\n",
    "In order to start the analysis, we check the datatypes of the columns and how many nulls are on each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid       float64\n",
       "i94yr       float64\n",
       "i94mon      float64\n",
       "i94cit      float64\n",
       "i94res      float64\n",
       "i94port      object\n",
       "arrdate     float64\n",
       "i94mode     float64\n",
       "i94addr      object\n",
       "depdate     float64\n",
       "i94bir      float64\n",
       "i94visa     float64\n",
       "count       float64\n",
       "dtadfile     object\n",
       "visapost     object\n",
       "occup        object\n",
       "entdepa      object\n",
       "entdepd      object\n",
       "entdepu      object\n",
       "matflag      object\n",
       "biryear     float64\n",
       "dtaddto      object\n",
       "gender       object\n",
       "insnum       object\n",
       "airline      object\n",
       "admnum      float64\n",
       "fltno        object\n",
       "visatype     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>biryear</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.847924e+06</td>\n",
       "      <td>2847924.0</td>\n",
       "      <td>2847924.0</td>\n",
       "      <td>2.847924e+06</td>\n",
       "      <td>2.847924e+06</td>\n",
       "      <td>2.847924e+06</td>\n",
       "      <td>2.847864e+06</td>\n",
       "      <td>2.325312e+06</td>\n",
       "      <td>2.846734e+06</td>\n",
       "      <td>2.847924e+06</td>\n",
       "      <td>2847924.0</td>\n",
       "      <td>2.846734e+06</td>\n",
       "      <td>2.847924e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.175194e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.276385e+02</td>\n",
       "      <td>3.266035e+02</td>\n",
       "      <td>2.046913e+04</td>\n",
       "      <td>1.064080e+00</td>\n",
       "      <td>2.048155e+04</td>\n",
       "      <td>3.754639e+01</td>\n",
       "      <td>1.951630e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.978454e+03</td>\n",
       "      <td>6.509401e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.801695e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.092268e+02</td>\n",
       "      <td>2.072825e+02</td>\n",
       "      <td>8.767172e+00</td>\n",
       "      <td>4.720415e-01</td>\n",
       "      <td>1.968092e+01</td>\n",
       "      <td>1.694457e+01</td>\n",
       "      <td>5.625815e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.694457e+01</td>\n",
       "      <td>2.321702e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>2.045400e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.499100e+04</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.905000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.663577e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>2.046200e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.047000e+04</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.966000e+03</td>\n",
       "      <td>4.506536e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.313376e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.450000e+02</td>\n",
       "      <td>2.450000e+02</td>\n",
       "      <td>2.046900e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.048000e+04</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.980000e+03</td>\n",
       "      <td>8.417651e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.692311e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.740000e+02</td>\n",
       "      <td>5.280000e+02</td>\n",
       "      <td>2.047700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.048800e+04</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.992000e+03</td>\n",
       "      <td>8.564061e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.148395e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>7.600000e+02</td>\n",
       "      <td>2.048400e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.144200e+04</td>\n",
       "      <td>1.110000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.018000e+03</td>\n",
       "      <td>9.913271e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cicid      i94yr     i94mon        i94cit        i94res  \\\n",
       "count  2.847924e+06  2847924.0  2847924.0  2.847924e+06  2.847924e+06   \n",
       "mean   3.175194e+06     2016.0        1.0  3.276385e+02  3.266035e+02   \n",
       "std    1.801695e+06        0.0        0.0  2.092268e+02  2.072825e+02   \n",
       "min    7.000000e+00     2016.0        1.0  1.010000e+02  1.010000e+02   \n",
       "25%    1.663577e+06     2016.0        1.0  1.480000e+02  1.350000e+02   \n",
       "50%    3.313376e+06     2016.0        1.0  2.450000e+02  2.450000e+02   \n",
       "75%    4.692311e+06     2016.0        1.0  5.740000e+02  5.280000e+02   \n",
       "max    6.148395e+06     2016.0        1.0  9.990000e+02  7.600000e+02   \n",
       "\n",
       "            arrdate       i94mode       depdate        i94bir       i94visa  \\\n",
       "count  2.847924e+06  2.847864e+06  2.325312e+06  2.846734e+06  2.847924e+06   \n",
       "mean   2.046913e+04  1.064080e+00  2.048155e+04  3.754639e+01  1.951630e+00   \n",
       "std    8.767172e+00  4.720415e-01  1.968092e+01  1.694457e+01  5.625815e-01   \n",
       "min    2.045400e+04  0.000000e+00  1.499100e+04 -2.000000e+00  1.000000e+00   \n",
       "25%    2.046200e+04  1.000000e+00  2.047000e+04  2.400000e+01  2.000000e+00   \n",
       "50%    2.046900e+04  1.000000e+00  2.048000e+04  3.600000e+01  2.000000e+00   \n",
       "75%    2.047700e+04  1.000000e+00  2.048800e+04  5.000000e+01  2.000000e+00   \n",
       "max    2.048400e+04  9.000000e+00  3.144200e+04  1.110000e+02  3.000000e+00   \n",
       "\n",
       "           count       biryear        admnum  \n",
       "count  2847924.0  2.846734e+06  2.847924e+06  \n",
       "mean         1.0  1.978454e+03  6.509401e+10  \n",
       "std          0.0  1.694457e+01  2.321702e+10  \n",
       "min          1.0  1.905000e+03  0.000000e+00  \n",
       "25%          1.0  1.966000e+03  4.506536e+10  \n",
       "50%          1.0  1.980000e+03  8.417651e+10  \n",
       "75%          1.0  1.992000e+03  8.564061e+10  \n",
       "max          1.0  2.018000e+03  9.913271e+10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid             0\n",
       "i94yr             0\n",
       "i94mon            0\n",
       "i94cit            0\n",
       "i94res            0\n",
       "i94port           0\n",
       "arrdate           0\n",
       "i94mode          60\n",
       "i94addr      177076\n",
       "depdate      522612\n",
       "i94bir         1190\n",
       "i94visa           0\n",
       "count             0\n",
       "dtadfile      90486\n",
       "visapost    1386375\n",
       "occup       2802355\n",
       "entdepa          61\n",
       "entdepd      521813\n",
       "entdepu     2847880\n",
       "matflag      521813\n",
       "biryear        1190\n",
       "dtaddto         707\n",
       "gender       216929\n",
       "insnum      2709236\n",
       "airline       61279\n",
       "admnum            0\n",
       "fltno         12232\n",
       "visatype          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It's important to notice that the PK of the table is *cicid* (and has no nulls) and that the field *i94port* (that has the code of the airport) also has no nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "From the previous analysis we see that :\n",
    "\n",
    "* Columns **insnum, matflag, entdepu, occup and visapost** can be dropped of the study because they are populated with too many nulls. \n",
    "\n",
    "* Dropping the previous columns, the fields that might seem useful to form the fact table that will feed analytical model are: **cicid**(primary key of the table), **i94yr**(year),  **i94mon**(month), **i94cit**(city code), **i94res**(residence country code), **i94port**(code for arrival port), **arrdate**(year with 4 digits), **i94mode**(year with 4 digits), **depdate**(departure date), **i94visa**(cause of the travel), **gender** and **airline**.\n",
    "\n",
    "* Several of this chosen columns haven't the right datatype. We are going to cast them into their correct datatype: **cicid** should be integer, **i94yr** should be integer,  **i94mon** should be integer, **i94cit** should be integer, **i94res** should be integer, **i94port** is a string, **arrdate** should be date, **i94mode** is float and should be integer, **depdate** should be date, **i94visa** should be integer, **gender** is string and **airline** is string.\n",
    "\n",
    "* According to the indications given in the lessons, **we will create a dimension table with every date** in this table and write several aspects of each date (day, year, month, week of the year, day of the week, etcetera). As an observation, the fields **arrdate** and **deptdate** indicates the number of days between the 1st of January of 1960 and today, so we'll have to process it correctly.\n",
    "\n",
    "* We can make some feature engineering columns that increase funcional value to the analysis.\n",
    "\n",
    "* All this steps and the corresponding save of the tables into AWS S3 buckets its done in the productivized script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.3. Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A complete description of the dataset *GlobalLandTemperaturesByCity.csv.csv* that has been given can be found on the page  of Kaggle https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data. There they explain how this dataset has been built and the different sources that feed it: NOAA’s MLOST, NASA’s GISTEMP and the UK’s HadCrut.\n",
    "\n",
    "We are interested in studying the mean temperature by state the last 20 years to join this info to the demographic data on state. That's why we are going to get external data from https://simplemaps.com/data/world-cities to put the state of each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>35.6850</td>\n",
       "      <td>139.7514</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>primary</td>\n",
       "      <td>35676000.0</td>\n",
       "      <td>1392685764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19354922.0</td>\n",
       "      <td>1840034016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>19.4424</td>\n",
       "      <td>-99.1310</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>MX</td>\n",
       "      <td>MEX</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>primary</td>\n",
       "      <td>19028000.0</td>\n",
       "      <td>1484247881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.0170</td>\n",
       "      <td>72.8570</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>admin</td>\n",
       "      <td>18978000.0</td>\n",
       "      <td>1356226629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>-23.5587</td>\n",
       "      <td>-46.6250</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>BRA</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>admin</td>\n",
       "      <td>18845000.0</td>\n",
       "      <td>1076532519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city   city_ascii      lat       lng        country iso2 iso3  \\\n",
       "0        Tokyo        Tokyo  35.6850  139.7514          Japan   JP  JPN   \n",
       "1     New York     New York  40.6943  -73.9249  United States   US  USA   \n",
       "2  Mexico City  Mexico City  19.4424  -99.1310         Mexico   MX  MEX   \n",
       "3       Mumbai       Mumbai  19.0170   72.8570          India   IN  IND   \n",
       "4    São Paulo    Sao Paulo -23.5587  -46.6250         Brazil   BR  BRA   \n",
       "\n",
       "         admin_name  capital  population          id  \n",
       "0             Tōkyō  primary  35676000.0  1392685764  \n",
       "1          New York      NaN  19354922.0  1840034016  \n",
       "2  Ciudad de México  primary  19028000.0  1484247881  \n",
       "3       Mahārāshtra    admin  18978000.0  1356226629  \n",
       "4         São Paulo    admin  18845000.0  1076532519  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities = pd.read_csv('external_data/worldcities.csv')\n",
    "worldcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we said, we are only interested on US cities, so we filter the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities = worldcities[(worldcities['country'] == \"United States\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We get a dataframe with each city in US and its corresponding state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dict_city_state = us_cities.groupby(['city'], as_index=False).agg({'admin_name': \"first\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we load the world temperature dataset from Kaggle (as described before) and cast its *dt* column to have a datetime datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temperatures = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_temperatures['dt'] = pd.to_datetime(df_temperatures.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We select only data corresponding to US and with AverageTemperature completed. Furthermore, as temperature trends has been modified due to climate change, we only consider the last 20 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp_us = df_temperatures[(df_temperatures['Country'] == \"United States\") & \\\n",
    "                             (df_temperatures['AverageTemperature'].notnull()) & \\\n",
    "                             (df_temperatures['dt'] > '2000-01-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we enrich this dataframe with the state that we have got before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = pd.merge(df_temp_us, dict_city_state, left_on=['City'], right_on=['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "And calculate the mean of Temperature by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_state = temp_df.groupby(['admin_name'], as_index=False).agg({'AverageTemperature': \"mean\", 'Latitude': \"first\",'Longitude': 'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin_name</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>17.884701</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>87.13W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>-0.925859</td>\n",
       "      <td>61.88N</td>\n",
       "      <td>151.13W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>20.819293</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>112.02W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>17.415079</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>79.78W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>16.302102</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>117.77W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admin_name  AverageTemperature Latitude Longitude\n",
       "0     Alabama           17.884701   32.95N    87.13W\n",
       "1      Alaska           -0.925859   61.88N   151.13W\n",
       "2     Arizona           20.819293   32.95N   112.02W\n",
       "3    Arkansas           17.415079   34.56N    79.78W\n",
       "4  California           16.302102   32.95N   117.77W"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Looking at I94 immigration data, we can check that the state is a two letter code. So to be able to join the previous table, we need to map the state name and that is why we load a table with this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "states_code = pd.read_csv('external_data/statesabbr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbrev</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Ala.</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Ariz.</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Ark.</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Calif.</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Abbrev Code\n",
       "0     Alabama    Ala.   AL\n",
       "1      Alaska  Alaska   AK\n",
       "2     Arizona   Ariz.   AZ\n",
       "3    Arkansas    Ark.   AR\n",
       "4  California  Calif.   CA"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_states_temp = pd.merge(temp_state, \\\n",
    "                          states_code, \\\n",
    "                          left_on=['admin_name'], \\\n",
    "                          right_on=['State'])[['Code', 'AverageTemperature', 'Latitude', 'Longitude']]\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_states_code = df_states_temp.rename(columns={'Code': 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>17.884701</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>87.13W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>-0.925859</td>\n",
       "      <td>61.88N</td>\n",
       "      <td>151.13W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>20.819293</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>112.02W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>17.415079</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>79.78W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>16.302102</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>117.77W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  AverageTemperature Latitude Longitude\n",
       "0    AL           17.884701   32.95N    87.13W\n",
       "1    AK           -0.925859   61.88N   151.13W\n",
       "2    AZ           20.819293   32.95N   112.02W\n",
       "3    AR           17.415079   34.56N    79.78W\n",
       "4    CA           16.302102   32.95N   117.77W"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "With the previous data, we will enrich the table with information of states. But furthermore, we would like to increase the data of the immigration data. That's why in the next cell we compute an aggregation of temperature by country in the last 20 years (same temporal filter than the other computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temperatures_country = df_temperatures.groupby(['Country'], as_index=False)\\\n",
    "                                         .agg({'AverageTemperature': \"mean\", 'Latitude': \"first\",'Longitude': 'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>13.816497</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>15.525828</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>19.17E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>17.763206</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>3.98E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>21.759716</td>\n",
       "      <td>12.05S</td>\n",
       "      <td>13.15E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>16.999216</td>\n",
       "      <td>39.38S</td>\n",
       "      <td>62.43W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  AverageTemperature Latitude Longitude\n",
       "0  Afghanistan           13.816497   36.17N    69.61E\n",
       "1      Albania           15.525828   40.99N    19.17E\n",
       "2      Algeria           17.763206   36.17N     3.98E\n",
       "3       Angola           21.759716   12.05S    13.15E\n",
       "4    Argentina           16.999216   39.38S    62.43W"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperatures_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This table will be used as a \"Countries\" dimension in our Snowflake data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.4. Airport Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As can be found in https://datahub.io/core/airport-codes#readme: *The airport codes may refer to either IATA airport code, a three-letter code which is used in passenger reservation, ticketing and baggage-handling systems, or the ICAO airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport = pd.read_csv(\"airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>03N</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Utirik Airport</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH-UTI</td>\n",
       "      <td>Utirik Island</td>\n",
       "      <td>K03N</td>\n",
       "      <td>UTK</td>\n",
       "      <td>03N</td>\n",
       "      <td>169.852005, 11.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803161621, 25.325399398804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PQS</td>\n",
       "      <td>0AK</td>\n",
       "      <td>-162.899994, 61.934601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>CSE</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>-106.928341, 38.851918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>JCY</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>-98.62249755859999, 30.251800537100003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident           type                     name  elevation_ft continent  \\\n",
       "223    03N  small_airport           Utirik Airport           4.0        OC   \n",
       "440   07FA  small_airport  Ocean Reef Club Airport           8.0       NaN   \n",
       "594    0AK  small_airport    Pilot Station Airport         305.0       NaN   \n",
       "673   0CO2  small_airport    Crested Butte Airpark        8980.0       NaN   \n",
       "1088  0TE7  small_airport        LBJ Ranch Airport        1515.0       NaN   \n",
       "\n",
       "     iso_country iso_region   municipality gps_code iata_code local_code  \\\n",
       "223           MH     MH-UTI  Utirik Island     K03N       UTK        03N   \n",
       "440           US      US-FL      Key Largo     07FA       OCA       07FA   \n",
       "594           US      US-AK  Pilot Station      NaN       PQS        0AK   \n",
       "673           US      US-CO  Crested Butte     0CO2       CSE       0CO2   \n",
       "1088          US      US-TX   Johnson City     0TE7       JCY       0TE7   \n",
       "\n",
       "                                 coordinates  \n",
       "223                       169.852005, 11.222  \n",
       "440        -80.274803161621, 25.325399398804  \n",
       "594                   -162.899994, 61.934601  \n",
       "673                   -106.928341, 38.851918  \n",
       "1088  -98.62249755859999, 30.251800537100003  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df = airport[~airport['iata_code'].isnull()]\n",
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_data = airport_df[['name', 'iso_country', 'iso_region', 'municipality', 'iata_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>iata_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Utirik Airport</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH-UTI</td>\n",
       "      <td>Utirik Island</td>\n",
       "      <td>UTK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>OCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>PQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>CSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>JCY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name iso_country iso_region   municipality iata_code\n",
       "223            Utirik Airport          MH     MH-UTI  Utirik Island       UTK\n",
       "440   Ocean Reef Club Airport          US      US-FL      Key Largo       OCA\n",
       "594     Pilot Station Airport          US      US-AK  Pilot Station       PQS\n",
       "673     Crested Butte Airpark          US      US-CO  Crested Butte       CSE\n",
       "1088        LBJ Ranch Airport          US      US-TX   Johnson City       JCY"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.5. USA City Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. \n",
    "\n",
    "This data comes from the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities_demographics = pd.read_csv(\"us-cities-demographics.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In order to understand the data better, we fixed a city and take a look into the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>40.4</td>\n",
       "      <td>215840.0</td>\n",
       "      <td>225149.0</td>\n",
       "      <td>440989</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>260789.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>FL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>40.4</td>\n",
       "      <td>215840.0</td>\n",
       "      <td>225149.0</td>\n",
       "      <td>440989</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>260789.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>319942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>40.4</td>\n",
       "      <td>215840.0</td>\n",
       "      <td>225149.0</td>\n",
       "      <td>440989</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>260789.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>87331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>40.4</td>\n",
       "      <td>215840.0</td>\n",
       "      <td>225149.0</td>\n",
       "      <td>440989</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>260789.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>FL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>40.4</td>\n",
       "      <td>215840.0</td>\n",
       "      <td>225149.0</td>\n",
       "      <td>440989</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>260789.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>338232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City    State  Median Age  Male Population  Female Population  \\\n",
       "1420  Miami  Florida        40.4         215840.0           225149.0   \n",
       "1783  Miami  Florida        40.4         215840.0           225149.0   \n",
       "1784  Miami  Florida        40.4         215840.0           225149.0   \n",
       "2180  Miami  Florida        40.4         215840.0           225149.0   \n",
       "2376  Miami  Florida        40.4         215840.0           225149.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "1420            440989              7233.0      260789.0   \n",
       "1783            440989              7233.0      260789.0   \n",
       "1784            440989              7233.0      260789.0   \n",
       "2180            440989              7233.0      260789.0   \n",
       "2376            440989              7233.0      260789.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "1420                     2.5         FL                              Asian   \n",
       "1783                     2.5         FL                 Hispanic or Latino   \n",
       "1784                     2.5         FL          Black or African-American   \n",
       "2180                     2.5         FL  American Indian and Alaska Native   \n",
       "2376                     2.5         FL                              White   \n",
       "\n",
       "       Count  \n",
       "1420    4613  \n",
       "1783  319942  \n",
       "1784   87331  \n",
       "2180    1571  \n",
       "2376  338232  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_demographics[us_cities_demographics['City'] == \"Miami\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It can be checked that all the fields for one city have the same info, except race and count. So we are going to pivot this table to have one row per city with so many columns of races as data is into it and the count by race.\n",
    "\n",
    "This official dataset is going to be the source of info about states, so I have decided to group by state and aggregate properly. When this will be done, we'll can join the temperature info obtained by state previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3. Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "\n",
    "I have chosen to develop a star model. It is shown in the next diagram:\n",
    "\n",
    "![image info](./model.png)\n",
    "\n",
    "Let's explain a bit the previous graphic: \n",
    "\n",
    "* I94 table is the fact model, containing the info that it's been cleaned and selected from original files.\n",
    "* From the date fields of it, we have created a dimension called Date with different aspects of this dates, such us month, year or day of the week.\n",
    "* A dimension table that specify average temperature by US State.\n",
    "* A dimension table that specify average temperature by world country.\n",
    "* A dimension with IATA codes of different US airports.\n",
    "* A table with demographical information of each US state that is the \"Demographic Dimension\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "The different phases to reach this data model are the following:\n",
    "\n",
    "#### 3.2.1 etl.py\n",
    "\n",
    "I have structured this script in distinct parts that make the code much more easy to read:\n",
    "\n",
    "* Imports of libraries and modules.\n",
    "* Load of parameters and constants from .cfg file.\n",
    "* Design of ETL functions for distinct sources and UDFs. There are distinct ETL functions for i94 data, temperature dimension, airport dimension and demographic data. Each one loads their tables from their corresponding routes, processed them and loads into a subset of the AWS S3 bucket that has been created (`arc-udacity-dataengineer-project-capstone`).\n",
    "* Main: Executes the different functions with the appropiate paramethers.\n",
    "\n",
    "#### 3.2.2 Apache Airflow.\n",
    "\n",
    "Apache Airflow has been deployed on top of an M2.xlarge EC2 instance with OS Ubuntu18.04. The process of configuration followed to make an EC2 instance to be an  Airflow server is really well explained on https://medium.com/@abraham.pabbathi/airflow-on-aws-ec2-instance-with-ubuntu-aff8d3206171. Once we have made it, I have SSH into the IP of this EC2 instance and I have left the folder `airflow` with all the code and dependencies into `/home/airflow/`. Accessing to this IP adress throught the web browser, we Turn-On the `project_capstone_dend_dag` developed for this case of use and trigger it.\n",
    "\n",
    "Basically, it creates the metadata structure for each table of the model in AWS redshift, stages the data of different tables loaded previously in an S3 bucket into those tables and performs some quality checks to the proccess of load.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "\n",
    "Once the different code has been created, to make all the ETL we must run the python script from a CMD:\n",
    "\n",
    "`>> python etl.py`\n",
    "\n",
    "When the process is completed, the different tables in the model will be in the AWS S3 bucket we have configured. To stage the data into its corresponding AWS Redshift table, we run the Apache Airflow Dag launched in the Ubuntu EC2 instance that was configured and run it.\n",
    "\n",
    "![image info](./DAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Data quality checks have been performed by adding a step in the Apache Airflow Dag: DataQualityOperator.\n",
    "\n",
    "On its corresponding script, we have made the following two checks for each table in the model:\n",
    "\n",
    " * Tables have been created in Redshift (are not empty)\n",
    " * Each table have at least one record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "In this section we are describe each field on this datamodel.\n",
    "\n",
    "#### 4.3.1 Fact Table: i94_data\n",
    "\n",
    "| FIELD | MEANING |\n",
    "|-------------------|-----------------------------------------------|\n",
    "| cicid | ID of each row in this fact table |\n",
    "| i94yr | Year of completing the i94 form |\n",
    "| i94mon | Mear of completing the i94 form |\n",
    "| i94cit | Code: Born country of the traveler |\n",
    "| i94res | Code: Residence country of the traveler |\n",
    "| i94port | Code: Arrival airport |\n",
    "| arrdate | Arrival date |\n",
    "| i94mode | Code: Kind of transport |\n",
    "| depdate | Departure date |\n",
    "| i94visa | Code: Reason for the travel |\n",
    "| gender | Gender of the traveler |\n",
    "| airline | Company with which the traveler arrives |\n",
    "| airport_name | Description: Arrival airport |\n",
    "| state_code | Name of the state of arrival |\n",
    "| born_country | Description: Born country of the traveler |\n",
    "| residence_country | Description: Residence counry of the traveler |\n",
    "| mode | Description: Kind of transport |\n",
    "| visa | Description: Reason for the travel |\n",
    "\n",
    "#### 4.3.2 Dimension Table: Demographic\n",
    "\n",
    "| FIELD | MEANING |\n",
    "|-----------------------------------|----------------------------------------------------------------|\n",
    "| state | Name of the US state |\n",
    "| median_age | Median age of the population in the state |\n",
    "| male_population | Total number of men in the state |\n",
    "| female_population | Total number of women in the state |\n",
    "| total_population | Total number of people in the state |\n",
    "| number_of_veterans | Total number of veterans in the state |\n",
    "| foreign_borns | Total number of foreigners in the state |\n",
    "| average_household_size | Average size of a house in the state |\n",
    "| state_code | Code of the US state |\n",
    "| american_indian_and_alaska_native | Total number of american indian and Alaska nativesin the state |\n",
    "| asian | Total number of asian people in the state |\n",
    "| black_african_american | Total number of black african american people in the state |\n",
    "| hispanic_latino | Total number of latinos in the state |\n",
    "| white | Total number of white people in the state |\n",
    "\n",
    "#### 4.3.3 Dimension Table: Date\n",
    "\n",
    "| FIELD | MEANING |\n",
    "|---------|--------------------------------------------|\n",
    "| date | Date |\n",
    "| day | Day of the corresponding date |\n",
    "| month | Month of the corresponding date |\n",
    "| year | Year of the corresponding date |\n",
    "| week | Week of the year of the corresponding date |\n",
    "| weekday | Day of the week of the corresponding date |\n",
    "| yearday | Day of the year of the corresponding date |\n",
    "\n",
    "#### 4.3.4 Dimension Table: airports\n",
    "\n",
    "| FIELD | MEANING |\n",
    "|--------------|-----------------------------------|\n",
    "| name | Name of the airport |\n",
    "| iso_country | Country where the airport locates |\n",
    "| municipality | City where the airport locates |\n",
    "| iata_code | International code of the airport |\n",
    "| state | State where the airport locates |\n",
    "\n",
    "\n",
    "#### 4.3.5 Dimension Table: countries_temperature\n",
    "\n",
    "| FIELD | MEANING |\n",
    "|---------------------|-------------------------------------|\n",
    "| country | Name of the country |\n",
    "| average_temperature | Average temperature in that country |\n",
    "\n",
    "#### 4.3.6 Dimension Table: states_temperature\n",
    "\n",
    "| FIELD | MEANING |\n",
    "|---------------------|-----------------------------------|\n",
    "| state | Name of the US state |\n",
    "| average_temperature | Average temperature in that state |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 5. Complete Project Write Up\n",
    "\n",
    "#### 5.1. Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "The solution of the project that have different parts. The first one is doing an ETL over the different datasets. I've chosen doing it throught Spark scripts. As a result, output datasets are stored in AWS S3. An AWS EC2 instaced it has been launched and configured to have Apache Airflow and DAGS has been programed to be executed on this machine. As a result, it moves the files from S3 into Redshift and performs some checks on data.\n",
    "\n",
    "A possible improvement to this project would be uploading the initial data into other S3 buckets and deploying an EMR cluster where executing the spark-submit job.\n",
    "\n",
    "* **Spark**: As indicates its own documetation on https://spark.apache.org/docs/latest/: *Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.*\n",
    "\n",
    "* **AWS S3**: Amazon Simple Storage Service (S3) is a service offered by AWS that provides object scalable storage through a web service interface. AWS S3 can be employed to store any type of object which allows for uses like storage for Internet applications, backup and recovery, disaster recovery, data archives, data lakes for analytics, and hybrid cloud storage.\n",
    "\n",
    "* **Amazon Redshift**: Amazon Redshift is a data warehouse product which forms part of AWS. It can handle large scale data sets and database migrations. Redshift is able to handle analytic workloads on big data data sets stored by a column-oriented DBMS principle.\n",
    "\n",
    "* **Apache Airflow**: Apache Airflow is an open-source tool for orchestrating workflows and data processing pipelines. Python language is used to define tasks and combine them into a Directed Acyclic Graph (DAG) that executes the logic desired.\n",
    "\n",
    "* **AWS EC2**: Amazon Elastic Cloud Computing is a computing cloud solution that allow us to easily deploy IaaC machines and configuring them however we want. Apache Airflow has been deployed on top of M2.xlarge EC2 instance with OS Ubuntu18.04. The process of configuration follow to make an EC2 instance an Apache Airflow server is really well explained on https://medium.com/@abraham.pabbathi/airflow-on-aws-ec2-instance-with-ubuntu-aff8d3206171\n",
    "\n",
    "#### 5.2. Propose how often the data should be updated and why.\n",
    "\n",
    "Since the fact table of our data model is feed with monthly I94 data files, we can suppose that the official department will create a batch of data each month. So updating once a month could be a criterion to refresh the data model.\n",
    "\n",
    "#### 5.3. Write a description of how you would approach the problem differently under the following scenarios:\n",
    "##### 5.3.1. The data was increased by 100x.\n",
    "\n",
    "If the increase of data was of this magnitude, the Spark script that performs the ETL should be run in a cluster with enough datanodes. Scalling the solution would move us to execute this part on a cloud solution. As it has been explained during the course, AWS ElasticMapReduce would fit great into solving this issue, since you could provide the enviroment the ability to scalling up or down the number of EC2 node instances depending on the workloads.\n",
    "\n",
    "##### 5.3.2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "As I proposed in the solution, using a data pipeline orchestator as Apache Airflow would be great to schedule tasks. It would syncronize the execution of different tasks automatically.\n",
    "\n",
    "##### 5.3.3. The database needed to be accessed by 100+ people.\n",
    "\n",
    "Since we have chosen AWS Redshift as our data warehose solution, this need of increase the people that access to the database would not be a problem. As other AWS solutions, there are options to scale the number of nodes in our cluster depending workloads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
